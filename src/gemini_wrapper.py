from typing import Union, List, Dict, Type
from langchain_core.runnables import Runnable, RunnableConfig
from langchain_core.messages import AIMessage, AnyMessage
from pydantic.v1 import BaseModel
from gemini_adapter import extract_and_store_thought_signatures, restore_thought_signatures


class Gemini3Wrapper(Runnable):
    """Wrapper to automatically handle thoughtSignature persistence."""
    def __init__(self, model):
        self.model = model

    def bind_tools(self, *args, **kwargs):
        """Supports bind_tools, returns the wrapped self."""
        return Gemini3Wrapper(self.model.bind_tools(*args, **kwargs))

    def with_structured_output(self, schema: Union[Dict, Type[BaseModel]], **kwargs):
        """
        Supports with_structured_output.
        
        This method usually returns a Runnable. We need to ensure that when this Runnable executes,
        it also benefits from the signature handling logic (although structured output is usually one-off,
        to maintain interface consistency, we directly call this method of the underlying model and ensure the input message is restored).
        """
        # Get the structured_output chain generated by the underlying model
        structured_chain = self.model.with_structured_output(schema, **kwargs)
        
        # Wrap a new Runnable to handle the restoration of input messages
        # Note: The output of structured_output is usually a Pydantic object or a dictionary, not an AIMessage anymore,
        # so the extract step is not needed.
        
        class StructuredOutputWrapper(Runnable):
            def __init__(self, chain):
                self.chain = chain
                
            def invoke(self, input, config=None, **kwargs):
                # Restore: Restore signature before sending
                messages_arg = input
                if isinstance(input, dict) and "messages" in input:
                    input["messages"] = restore_thought_signatures(input["messages"])
                elif isinstance(input, list):
                    messages_arg = restore_thought_signatures(input)
                    input = messages_arg
                    
                return self.chain.invoke(input, config=config, **kwargs)

            async def ainvoke(self, input, config=None, **kwargs):
                # Restore: Restore signature before sending (async)
                messages_arg = input
                if isinstance(input, dict) and "messages" in input:
                    input["messages"] = restore_thought_signatures(input["messages"])
                elif isinstance(input, list):
                    messages_arg = restore_thought_signatures(input)
                    input = messages_arg
                    
                return await self.chain.ainvoke(input, config=config, **kwargs)

        return StructuredOutputWrapper(structured_chain)

    async def ainvoke(self, input: Union[List[AnyMessage], Dict], config: RunnableConfig = None, **kwargs):
        # 1. Restore: Restore signature before sending
        messages_arg = input
        if isinstance(input, dict) and "messages" in input:
            input["messages"] = restore_thought_signatures(input["messages"])
        elif isinstance(input, list):
            messages_arg = restore_thought_signatures(input)
            input = messages_arg

        # 2. Invoke: Call the original model
        response = await self.model.ainvoke(input, config=config, **kwargs)

        # 3. Extract: Save signature after returning
        if isinstance(response, AIMessage):
            response = extract_and_store_thought_signatures(response)
            
        return response
    
    def invoke(self, input, config=None, **kwargs):
        # Synchronous Invoke support
        messages_arg = input
        if isinstance(input, dict) and "messages" in input:
            input["messages"] = restore_thought_signatures(input["messages"])
        elif isinstance(input, list):
            messages_arg = restore_thought_signatures(input)
            input = messages_arg

        response = self.model.invoke(input, config=config, **kwargs)

        if isinstance(response, AIMessage):
            response = extract_and_store_thought_signatures(response)
            
        return response
